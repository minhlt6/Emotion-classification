import streamlit as st
import joblib
import numpy as np
import cv2
from PIL import Image
import os
import gdown

# --- C·∫•u h√¨nh trang ph·∫£i n·∫±m ƒë·∫ßu ti√™n ---
st.set_page_config(layout="wide", page_title="Nh·∫≠n di·ªán c·∫£m x√∫c HOG")

class HOGDescriptor:
    def __init__(self, img_size=(64, 64), cell_size=(8, 8), block_size=(2, 2), bins=9):
        self.img_size = img_size
        self.cell_size = cell_size
        self.block_size = block_size
        self.bins = bins

    def process_image(self, img):
        # Chuy·ªÉn sang ·∫£nh x√°m n·∫øu l√† ·∫£nh m√†u
        if len(img.shape) == 3:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = cv2.resize(img, self.img_size)
        img = img.astype(np.float32) / 255.0
        return img

    def compute_gradients(self, img):
        kernel_x = np.array([-1, 0, 1])
        kernel_y = np.array([-1, 0, 1]).T
        gx = cv2.filter2D(img, -1, kernel_x)
        gy = cv2.filter2D(img, -1, kernel_y)
        magnitude = np.sqrt(gx**2 + gy**2)
        angle = np.arctan2(gy, gx) * (180 / np.pi)
        angle = angle % 180
        return magnitude, angle

    def compute_histograms(self, magnitude, angle):
        h, w = magnitude.shape
        cell_h, cell_w = self.cell_size
        n_cell_y = h // cell_h
        n_cell_x = w // cell_w
        histograms = np.zeros((n_cell_y, n_cell_x, self.bins))
        bin_width = 180 / self.bins

        for i in range(n_cell_y):
            for j in range(n_cell_x):
                cell_mag = magnitude[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w]
                cell_ang = angle[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w]
                for y in range(cell_h):
                    for x in range(cell_w):
                        mag = cell_mag[y, x]
                        ang = cell_ang[y, x]
                        bin_idx = int(ang // bin_width) % self.bins
                        next_bin_idx = (bin_idx + 1) % self.bins
                        weight = (ang % bin_width) / bin_width
                        histograms[i, j, bin_idx] += mag * (1 - weight)
                        histograms[i, j, next_bin_idx] += mag * weight
        return histograms

    def compute_block_normalization(self, histograms):
        n_cell_y, n_cell_x, _ = histograms.shape
        block_h, block_w = self.block_size
        n_block_y = n_cell_y - block_h + 1
        n_block_x = n_cell_x - block_w + 1
        normalized_blocks = []
        for i in range(n_block_y):
            for j in range(n_block_x):
                block = histograms[i:i+block_h, j:j+block_w].flatten()
                norm = np.sqrt(np.sum(block**2) + 1e-5)
                normalized_blocks.append(block / norm)
        return np.concatenate(normalized_blocks)

    def extract_features(self, img_array):
        processed_img = self.process_image(img_array)
        mag, ang = self.compute_gradients(processed_img)
        hist = self.compute_histograms(mag, ang)
        features = self.compute_block_normalization(hist)
        return features

# --- C·∫•u h√¨nh Model ---
MODEL_CONFIGS = {
    "Random Forest": {"id": "1PrrF8vO0xIBbcj8hkYHYQOoGHrr-bkqw", "file": "rf_model.pkl"},
    "ID3": {"id": "1_JTMBw1rBzvNs8SKW_s-eaF0kAhhZWhz", "file": "id3_model.pkl"},
    "CART": {"id": "1LeDg_XCMYGsr_WkM6fby7lcf0_W7Gk7c", "file": "cart_model.pkl"},
    "KNN": {"id": "1HzvDgRDlhkt7LvhvqPtwT5g-AVwhmDfA", "file": "knn_model.pkl"}
}

SELECTOR_FILENAME = 'selector.pkl'

@st.cache_resource
def load_all_models():
    loaded_models = {}
    selector = None
    
    # Load Selector n·∫øu c√≥
    if os.path.exists(SELECTOR_FILENAME):
        try:
            selector = joblib.load(SELECTOR_FILENAME)
        except Exception:
            pass # B·ªè qua n·∫øu l·ªói
    
    for name, config in MODEL_CONFIGS.items():
        file_path = config["file"]
        drive_id = config["id"]
        
        if not os.path.exists(file_path):
            url = f'https://drive.google.com/uc?id={drive_id}'
            try:
                gdown.download(url, file_path, quiet=True)
            except:
                st.warning(f"Kh√¥ng th·ªÉ t·∫£i model {name}")
                continue

        try:
            if os.path.exists(file_path):
                loaded_models[name] = joblib.load(file_path)
        except Exception as e:
            st.error(f"L·ªói load {name}: {e}")

    return loaded_models, selector

def process_image_input(image_pil, selector):
    # Chuy·ªÉn PIL Image sang Numpy array
    img_array = np.array(image_pil)
    
    # N·∫øu ·∫£nh c√≥ 4 k√™nh (PNG RGBA) th√¨ b·ªè k√™nh Alpha
    if len(img_array.shape) == 3 and img_array.shape[2] == 4:
        img_array = img_array[..., :3]
        
    hog_desc = HOGDescriptor(img_size=(64, 64), cell_size=(8, 8), block_size=(2, 2), bins=9)
    features = hog_desc.extract_features(img_array)
    features = features.reshape(1, -1)
    
    if selector:
        features = selector.transform(features)
    return features

# --- Giao di·ªán ch√≠nh ---
st.title("So s√°nh 4 thu·∫≠t to√°n: ID3 - CART - RF - KNN")
st.markdown("Demo nh·∫≠n di·ªán c·∫£m x√∫c s·ª≠ d·ª•ng ƒë·∫∑c tr∆∞ng HOG.")

models, selector = load_all_models()

if not models:
    st.error("Ch∆∞a load ƒë∆∞·ª£c model n√†o. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi m·∫°ng ho·∫∑c file model.")
else:
    st.success(f"ƒê√£ load th√†nh c√¥ng: {', '.join(models.keys())}")

# Chia c·ªôt giao di·ªán
col1, col2 = st.columns([1, 2])

# Bi·∫øn ƒë·ªÉ l∆∞u ·∫£nh ƒë·∫ßu v√†o t·ª´ ng∆∞·ªùi d√πng (d√π l√† upload hay camera)
input_image = None
source_type = None

with col1:
    st.subheader("ƒê·∫ßu v√†o")
    # T·∫°o Tab ƒë·ªÉ ng∆∞·ªùi d√πng ch·ªçn c√°ch nh·∫≠p ·∫£nh
    tab_upload, tab_cam = st.tabs(["üìÅ T·∫£i ·∫£nh l√™n", "üì∑ D√πng Camera"])
    
    with tab_upload:
        uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh t·ª´ m√°y...", type=["jpg", "png", "jpeg"])
        if uploaded_file is not None:
            input_image = Image.open(uploaded_file)
            source_type = "upload"
            
    with tab_cam:
        cam_image = st.camera_input("Ch·ª•p ·∫£nh khu√¥n m·∫∑t")
        if cam_image is not None:
            input_image = Image.open(cam_image)
            source_type = "camera"

    # Hi·ªÉn th·ªã ·∫£nh ƒë√£ ch·ªçn (n·∫øu l√† upload, camera t·ª± hi·ªÉn th·ªã r·ªìi)
    if input_image is not None and source_type == "upload":
        st.image(input_image, width=250, caption="·∫¢nh Input")

with col2:
    if input_image is not None and models:
        st.subheader("K·∫øt qu·∫£ d·ª± ƒëo√°n")
        
        # N√∫t b·∫•m d·ª± ƒëo√°n
        if st.button("Ch·∫°y d·ª± ƒëo√°n", type="primary"):
            with st.spinner('ƒêang tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng HOG v√† d·ª± ƒëo√°n...'):
                try:
                    # X·ª≠ l√Ω ƒë·∫∑c tr∆∞ng
                    features = process_image_input(input_image, selector)
                    
                    emotion_labels = {
                        0: "Angry (Gi·∫≠n d·ªØ)", 
                        1: "Fear (S·ª£ h√£i)", 
                        2: "Happy (Vui v·∫ª)", 
                        3: "Sad (Bu·ªìn)", 
                        4: "Surprise (Ng·∫°c nhi√™n)"
                    }

                    # Hi·ªÉn th·ªã k·∫øt qu·∫£ d·∫°ng l∆∞·ªõi
                    res_cols = st.columns(2) # Hi·ªÉn th·ªã 2 c·ªôt cho ƒë·∫πp
                    
                    for i, (model_name, model) in enumerate(models.items()):
                        # D·ª± ƒëo√°n
                        pred_idx = model.predict(features)[0]
                        pred_text = emotion_labels.get(pred_idx, f"L·ªõp {pred_idx}")
                        
                        # Hi·ªÉn th·ªã m√†u s·∫Øc kh√°c nhau cho t·ª´ng model ƒë·ªÉ d·ªÖ nh√¨n
                        with res_cols[i % 2]:
                            container = st.container(border=True)
                            container.markdown(f"**ü§ñ {model_name}**")
                            container.markdown(f"### {pred_text}")
                            
                except Exception as e:
                    st.error(f"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
                    st.exception(e) # In chi ti·∫øt l·ªói ƒë·ªÉ debug
    
    elif input_image is None:
        st.info("üëà Vui l√≤ng t·∫£i ·∫£nh l√™n ho·∫∑c ch·ª•p ·∫£nh ƒë·ªÉ b·∫Øt ƒë·∫ßu.")