import streamlit as st
import joblib
import numpy as np
import cv2
from PIL import Image
import os
import gdown

# --- Cáº¥u hÃ¬nh trang ---
st.set_page_config(layout="wide", page_title="Nháº­n diá»‡n cáº£m xÃºc HOG - Final")

# ==========================================
# 1. Cáº¤U HÃŒNH & LOAD MODEL
# ==========================================

# TÃªn file selector (Báº®T BUá»˜C PHáº¢I CÃ“ Ä‘á»ƒ giáº£m chiá»u vector)
SELECTOR_FILENAME = 'selector.pkl'

# ID Google Drive cá»§a file selector.pkl (Báº N HÃƒY ÄIá»€N ID Cá»¦A Báº N VÃ€O ÄÃ‚Y Náº¾U CÃ“)
# Náº¿u khÃ´ng, báº¡n pháº£i upload file selector.pkl lÃªn cÃ¹ng thÆ° má»¥c vá»›i app.py
SELECTOR_DRIVE_ID = None  # VÃ­ dá»¥: "1...ID_Cua_Ban..."

MODEL_CONFIGS = {
    "Random Forest": {"id": "1PrrF8vO0xIBbcj8hkYHYQOoGHrr-bkqw", "file": "rf_model.pkl"},
    "ID3": {"id": "1_JTMBw1rBzvNs8SKW_s-eaF0kAhhZWhz", "file": "id3_model.pkl"},
    "CART": {"id": "1LeDg_XCMYGsr_WkM6fby7lcf0_W7Gk7c", "file": "cart_model.pkl"},
    "KNN": {"id": "1HzvDgRDlhkt7LvhvqPtwT5g-AVwhmDfA", "file": "knn_model.pkl"}
}

@st.cache_resource
def load_resources():
    loaded_models = {}
    selector = None
    
    # 1. Táº£i vÃ  load Selector (QUAN TRá»ŒNG)
    if not os.path.exists(SELECTOR_FILENAME) and SELECTOR_DRIVE_ID:
        url = f'https://drive.google.com/uc?id={SELECTOR_DRIVE_ID}'
        try:
            gdown.download(url, SELECTOR_FILENAME, quiet=True)
        except: pass
        
    if os.path.exists(SELECTOR_FILENAME):
        try:
            selector = joblib.load(SELECTOR_FILENAME)
        except Exception as e:
            st.error(f"Lá»—i load selector.pkl: {e}")
    else:
        st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y file 'selector.pkl'. MÃ´ hÃ¬nh cÃ³ thá»ƒ bá»‹ lá»—i kÃ­ch thÆ°á»›c (Shape Mismatch)!")

    # 2. Táº£i vÃ  load Models
    for name, config in MODEL_CONFIGS.items():
        file_path = config["file"]
        drive_id = config["id"]
        
        if not os.path.exists(file_path):
            url = f'https://drive.google.com/uc?id={drive_id}'
            try:
                gdown.download(url, file_path, quiet=True)
            except: pass

        if os.path.exists(file_path):
            try:
                loaded_models[name] = joblib.load(file_path)
            except Exception as e:
                st.error(f"Lá»—i load {name}: {e}")
                
    return loaded_models, selector

# ==========================================
# 2. Xá»¬ LÃ áº¢NH & HOG (ÄÃ£ cáº­p nháº­t chuáº©n 64x64)
# ==========================================
class HOGDescriptor:
    def __init__(self, img_size=(64, 64), cell_size=(8, 8), block_size=(2, 2), bins=9):
        self.img_size = img_size
        self.cell_size = cell_size
        self.block_size = block_size
        self.bins = bins

    def process_image(self, img):
        if len(img.shape) == 3:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # 1. Resize vá» 64x64 (Báº®T BUá»˜C nhÆ° lÃºc train)
        img = cv2.resize(img, self.img_size)

        # 2. CÃ¢n báº±ng sÃ¡ng (Histogram Equalization) -> GiÃºp áº£nh Webcam rÃµ nÃ©t nhÆ° áº£nh train
        img = cv2.equalizeHist(img)
        
        # 3. LÃ m má» nháº¹ Ä‘á»ƒ khá»­ nhiá»…u webcam
        img = cv2.GaussianBlur(img, (3, 3), 0)

        # 4. Chuáº©n hÃ³a vá» 0-1
        img = img.astype(np.float32) / 255.0
        return img

    def compute_gradients(self, img):
        kernel_x = np.array([-1, 0, 1])
        kernel_y = np.array([-1, 0, 1]).T
        gx = cv2.filter2D(img, -1, kernel_x)
        gy = cv2.filter2D(img, -1, kernel_y)
        magnitude = np.sqrt(gx**2 + gy**2)
        angle = np.arctan2(gy, gx) * (180 / np.pi)
        angle = angle % 180
        return magnitude, angle

    def compute_histograms(self, magnitude, angle):
        h, w = magnitude.shape
        cell_h, cell_w = self.cell_size
        n_cell_y = h // cell_h
        n_cell_x = w // cell_w
        histograms = np.zeros((n_cell_y, n_cell_x, self.bins))
        bin_width = 180 / self.bins

        for i in range(n_cell_y):
            for j in range(n_cell_x):
                cell_mag = magnitude[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w]
                cell_ang = angle[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w]
                for y in range(cell_h):
                    for x in range(cell_w):
                        mag = cell_mag[y, x]
                        ang = cell_ang[y, x]
                        bin_idx = int(ang // bin_width) % self.bins
                        next_bin_idx = (bin_idx + 1) % self.bins
                        weight = (ang % bin_width) / bin_width
                        histograms[i, j, bin_idx] += mag * (1 - weight)
                        histograms[i, j, next_bin_idx] += mag * weight
        return histograms

    def compute_block_normalization(self, histograms):
        n_cell_y, n_cell_x, _ = histograms.shape
        block_h, block_w = self.block_size
        n_block_y = n_cell_y - block_h + 1
        n_block_x = n_cell_x - block_w + 1
        normalized_blocks = []
        for i in range(n_block_y):
            for j in range(n_block_x):
                block = histograms[i:i+block_h, j:j+block_w].flatten()
                norm = np.sqrt(np.sum(block**2) + 1e-5)
                normalized_blocks.append(block / norm)
        return np.concatenate(normalized_blocks)

    def extract_features(self, img_array):
        processed_img = self.process_image(img_array)
        mag, ang = self.compute_gradients(processed_img)
        hist = self.compute_histograms(mag, ang)
        features = self.compute_block_normalization(hist)
        return features

# ==========================================
# 3. HÃ€M Cáº®T Máº¶T (TIGHT CROP)
# ==========================================
def detect_face(image_array):
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    
    if len(faces) == 0:
        return None, None
    
    faces = sorted(faces, key=lambda x: x[2]*x[3], reverse=True)
    x, y, w, h = faces[0]
    
    # --- Cáº®T SÃT (ZOOM IN) ---
    # Thu háº¹p 15% viá»n Ä‘á»ƒ loáº¡i bá» tÃ³c/cá»•, chá»‰ láº¥y nÃ©t máº·t chÃ­nh
    zoom_ratio = 0.15 
    offset_x = int(w * zoom_ratio)
    offset_y = int(h * zoom_ratio)
    
    new_x = x + offset_x
    new_y = y + offset_y
    new_w = w - (2 * offset_x)
    new_h = h - (2 * offset_y)
    
    if new_w > 0 and new_h > 0:
        best_face = image_array[new_y:new_y+new_h, new_x:new_x+new_w]
        return best_face, (new_x, new_y, new_w, new_h)
    else:
        return image_array[y:y+h, x:x+w], (x, y, w, h)

# ==========================================
# 4. GIAO DIá»†N CHÃNH
# ==========================================
st.title("PhÃ¢n loáº¡i cáº£m xÃºc: ID3 - CART - RF - KNN")
st.markdown("Quy trÃ¬nh: Detect Face -> Crop -> HOG -> **Feature Selection (Giáº£m chiá»u)** -> Predict")

models, selector = load_resources()

if selector:
    st.success(f"âœ… ÄÃ£ táº£i Selector: {type(selector).__name__} (Sáºµn sÃ ng giáº£m chiá»u vector)")
else:
    st.error("âŒ ChÆ°a táº£i Ä‘Æ°á»£c file selector.pkl. Vui lÃ²ng kiá»ƒm tra!")

col1, col2 = st.columns([1, 1.5])
input_image_pil = None

with col1:
    st.subheader("1. Nháº­p áº£nh")
    tab_upload, tab_cam = st.tabs(["ðŸ“ Upload", "ðŸ“· Camera"])
    
    with tab_upload:
        uploaded_file = st.file_uploader("Chá»n áº£nh...", type=["jpg", "png", "jpeg"])
        if uploaded_file:
            input_image_pil = Image.open(uploaded_file)
    with tab_cam:
        cam_image = st.camera_input("Chá»¥p áº£nh")
        if cam_image:
            input_image_pil = Image.open(cam_image)

    if input_image_pil:
        input_array = np.array(input_image_pil)
        if len(input_array.shape) == 3 and input_array.shape[2] == 4:
            input_array = input_array[..., :3]

        st.info("Äang tÃ¬m khuÃ´n máº·t...")
        face_img, coords = detect_face(input_array)

        if face_img is not None:
            st.image(face_img, caption="KhuÃ´n máº·t Ä‘Ã£ cáº¯t (Input cho Model)", width=150)
            st.session_state['face_to_process'] = face_img
        else:
            st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y khuÃ´n máº·t rÃµ rÃ ng. DÃ¹ng toÃ n bá»™ áº£nh.")
            st.session_state['face_to_process'] = input_array

with col2:
    st.subheader("2. Káº¿t quáº£ dá»± Ä‘oÃ¡n")
    
    if 'face_to_process' in st.session_state and input_image_pil is not None:
        if st.button("Cháº¡y dá»± Ä‘oÃ¡n", type="primary"):
            face_to_analyze = st.session_state['face_to_process']
            
            with st.spinner('Äang xá»­ lÃ½...'):
                try:
                    # 1. TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng HOG
                    hog_desc = HOGDescriptor() # Máº·c Ä‘á»‹nh 64x64
                    features = hog_desc.extract_features(face_to_analyze)
                    features = features.reshape(1, -1)
                    
                    st.write(f"Sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng gá»‘c: **{features.shape[1]}**")

                    # 2. GIáº¢M CHIá»€U (FEATURE SELECTION) - QUAN TRá»ŒNG
                    if selector:
                        features = selector.transform(features)
                        st.write(f"Sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng sau khi giáº£m: **{features.shape[1]}**")
                    else:
                        st.error("Thiáº¿u selector.pkl, khÃ´ng thá»ƒ giáº£m chiá»u Ä‘áº·c trÆ°ng -> CÃ³ thá»ƒ gÃ¢y lá»—i!")

                    # 3. Dá»± Ä‘oÃ¡n
                    emotion_labels = {0: "Giáº­n dá»¯ ðŸ˜¡", 1: "Sá»£ hÃ£i ðŸ˜±", 2: "Vui váº» ðŸ˜„", 3: "Buá»“n ðŸ˜¢", 4: "Ngáº¡c nhiÃªn ðŸ˜²"}
                    
                    st.write("---")
                    res_cols = st.columns(2)
                    for i, (name, model) in enumerate(models.items()):
                        try:
                            pred = model.predict(features)[0]
                            label = emotion_labels.get(pred, str(pred))
                            with res_cols[i % 2]:
                                st.success(f"**{name}**: {label}")
                        except Exception as e:
                             with res_cols[i % 2]:
                                st.error(f"{name} lá»—i: {e}")

                except Exception as e:
                    st.error(f"Lá»—i chung: {e}")