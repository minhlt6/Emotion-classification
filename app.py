import streamlit as st
import joblib
import numpy as np
import cv2
from PIL import Image
import os
import gdown

# --- C·∫•u h√¨nh trang ---
st.set_page_config(layout="wide", page_title="Nh·∫≠n di·ªán c·∫£m x√∫c HOG")

# ==========================================
# 1. H√ÄM X·ª¨ L√ù ·∫¢NH & HOG
# ==========================================
class HOGDescriptor:
    def __init__(self, img_size=(64, 64), cell_size=(8, 8), block_size=(2, 2), bins=9):
        self.img_size = img_size
        self.cell_size = cell_size
        self.block_size = block_size
        self.bins = bins

    def process_image(self, img):
        # L∆∞u √Ω: img ·ªü ƒë√¢y l√† ·∫£nh ƒë√£ ƒë∆∞·ª£c c·∫Øt m·∫∑t
        if len(img.shape) == 3:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = cv2.resize(img, self.img_size)
        img = img.astype(np.float32) / 255.0
        return img

    def compute_gradients(self, img):
        kernel_x = np.array([-1, 0, 1])
        kernel_y = np.array([-1, 0, 1]).T
        gx = cv2.filter2D(img, -1, kernel_x)
        gy = cv2.filter2D(img, -1, kernel_y)
        magnitude = np.sqrt(gx**2 + gy**2)
        angle = np.arctan2(gy, gx) * (180 / np.pi)
        angle = angle % 180
        return magnitude, angle

    def compute_histograms(self, magnitude, angle):
        h, w = magnitude.shape
        cell_h, cell_w = self.cell_size
        n_cell_y = h // cell_h
        n_cell_x = w // cell_w
        histograms = np.zeros((n_cell_y, n_cell_x, self.bins))
        bin_width = 180 / self.bins

        for i in range(n_cell_y):
            for j in range(n_cell_x):
                cell_mag = magnitude[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w]
                cell_ang = angle[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w]
                for y in range(cell_h):
                    for x in range(cell_w):
                        mag = cell_mag[y, x]
                        ang = cell_ang[y, x]
                        bin_idx = int(ang // bin_width) % self.bins
                        next_bin_idx = (bin_idx + 1) % self.bins
                        weight = (ang % bin_width) / bin_width
                        histograms[i, j, bin_idx] += mag * (1 - weight)
                        histograms[i, j, next_bin_idx] += mag * weight
        return histograms

    def compute_block_normalization(self, histograms):
        n_cell_y, n_cell_x, _ = histograms.shape
        block_h, block_w = self.block_size
        n_block_y = n_cell_y - block_h + 1
        n_block_x = n_cell_x - block_w + 1
        normalized_blocks = []
        for i in range(n_block_y):
            for j in range(n_block_x):
                block = histograms[i:i+block_h, j:j+block_w].flatten()
                norm = np.sqrt(np.sum(block**2) + 1e-5)
                normalized_blocks.append(block / norm)
        return np.concatenate(normalized_blocks)

    def extract_features(self, img_array):
        processed_img = self.process_image(img_array)
        mag, ang = self.compute_gradients(processed_img)
        hist = self.compute_histograms(mag, ang)
        features = self.compute_block_normalization(hist)
        return features

# ==========================================
# 2. H√ÄM C·∫ÆT M·∫∂T 
def detect_face(image_array):
    """
    H√†m ph√°t hi·ªán v√† c·∫Øt khu√¥n m·∫∑t l·ªõn nh·∫•t trong ·∫£nh.
    Input: Numpy array (RGB)
    Output: Numpy array (RGB) ch·ª©a khu√¥n m·∫∑t ƒë√£ c·∫Øt, ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y.
    """
    # Load m√¥ h√¨nh nh·∫≠n di·ªán khu√¥n m·∫∑t c√≥ s·∫µn c·ªßa OpenCV
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    
    # Chuy·ªÉn sang ·∫£nh x√°m ƒë·ªÉ detect
    gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)
    
    # Ph√°t hi·ªán khu√¥n m·∫∑t
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    
    if len(faces) == 0:
        return None, None # Kh√¥ng t√¨m th·∫•y m·∫∑t
    
    # N·∫øu t√¨m th·∫•y nhi·ªÅu m·∫∑t, l·∫•y m·∫∑t c√≥ di·ªán t√≠ch l·ªõn nh·∫•t 
    max_area = 0
    best_face = None
    coords = None
    
    for (x, y, w, h) in faces:
        area = w * h
        if area > max_area:
            max_area = area
            # C·∫Øt ·∫£nh g·ªëc theo t·ªça ƒë·ªô (l∆∞u √Ω ·∫£nh g·ªëc l√† RGB)
            best_face = image_array[y:y+h, x:x+w]
            coords = (x, y, w, h)
            
    return best_face, coords

# ==========================================
# 3. QU·∫¢N L√ù MODEL
# ==========================================
MODEL_CONFIGS = {
    "Random Forest": {"id": "1PrrF8vO0xIBbcj8hkYHYQOoGHrr-bkqw", "file": "rf_model.pkl"},
    "ID3": {"id": "1_JTMBw1rBzvNs8SKW_s-eaF0kAhhZWhz", "file": "id3_model.pkl"},
    "CART": {"id": "1LeDg_XCMYGsr_WkM6fby7lcf0_W7Gk7c", "file": "cart_model.pkl"},
    "KNN": {"id": "1HzvDgRDlhkt7LvhvqPtwT5g-AVwhmDfA", "file": "knn_model.pkl"}
}

SELECTOR_FILENAME = 'selector.pkl'

@st.cache_resource
def load_all_models():
    loaded_models = {}
    selector = None
    
    if os.path.exists(SELECTOR_FILENAME):
        try:
            selector = joblib.load(SELECTOR_FILENAME)
        except: pass
    
    for name, config in MODEL_CONFIGS.items():
        file_path = config["file"]
        drive_id = config["id"]
        
        if not os.path.exists(file_path):
            url = f'https://drive.google.com/uc?id={drive_id}'
            try:
                gdown.download(url, file_path, quiet=True)
            except:
                st.warning(f"Kh√¥ng th·ªÉ t·∫£i model {name}")
                continue
             
        try:
            if os.path.exists(file_path):
                loaded_models[name] = joblib.load(file_path)
        except Exception as e:
            st.error(f"L·ªói load {name}: {e}")

    return loaded_models, selector

# H√†m tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ ·∫£nh ƒë√£ c·∫Øt
def extract_features_from_face(face_img_array, selector):
    hog_desc = HOGDescriptor(img_size=(64, 64), cell_size=(8, 8), block_size=(2, 2), bins=9)
    features = hog_desc.extract_features(face_img_array)
    features = features.reshape(1, -1)
    if selector:
        features = selector.transform(features)
    return features

# ==========================================
# 4. GIAO DI·ªÜN CH√çNH
# ==========================================
st.title("Ph√¢n lo·∫°i c·∫£m x√∫c: ID3 - CART - RF - KNN")
st.markdown("C√≥ t√≠ch h·ª£p: **T·ª± ƒë·ªông c·∫Øt khu√¥n m·∫∑t** tr∆∞·ªõc khi d·ª± ƒëo√°n.")

models, selector = load_all_models()

col1, col2 = st.columns([1, 1.5])

input_image_pil = None

with col1:
    st.subheader("1. Nh·∫≠p ·∫£nh")
    tab_upload, tab_cam = st.tabs(["üìÅ Upload", "üì∑ Camera"])
    
    with tab_upload:
        uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh...", type=["jpg", "png", "jpeg"])
        if uploaded_file:
            input_image_pil = Image.open(uploaded_file)
            
    with tab_cam:
        cam_image = st.camera_input("Ch·ª•p ·∫£nh")
        if cam_image:
            input_image_pil = Image.open(cam_image)

    # N·∫øu c√≥ ·∫£nh ƒë·∫ßu v√†o
    if input_image_pil:
        # Hi·ªÉn th·ªã ·∫£nh g·ªëc
        st.image(input_image_pil, caption="·∫¢nh g·ªëc", width=300)
        
        # Chuy·ªÉn sang array
        input_array = np.array(input_image_pil)
        if len(input_array.shape) == 3 and input_array.shape[2] == 4:
            input_array = input_array[..., :3] # B·ªè k√™nh alpha

        # --- GIAI ƒêO·∫†N C·∫ÆT M·∫∂T ---
        st.info("ƒêang t√¨m khu√¥n m·∫∑t...")
        face_img, coords = detect_face(input_array)

        if face_img is not None:
            # V·∫Ω h√¨nh ch·ªØ nh·∫≠t l√™n ·∫£nh g·ªëc ƒë·ªÉ minh h·ªça (Optional)
            x, y, w, h = coords
            cv2.rectangle(input_array, (x, y), (x+w, y+h), (0, 255, 0), 2)
            
            st.success("‚úÖ ƒê√£ t√¨m th·∫•y khu√¥n m·∫∑t!")
            st.image(face_img, caption="Khu√¥n m·∫∑t ƒë√£ c·∫Øt (Input cho Model)", width=150)
            
            # L∆∞u khu√¥n m·∫∑t v√†o bi·∫øn session state ho·∫∑c bi·∫øn t·∫°m ƒë·ªÉ d√πng ·ªü c·ªôt b√™n kia
            st.session_state['face_to_process'] = face_img
        else:
            st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t r√µ r√†ng. S·∫Ω d√πng to√†n b·ªô ·∫£nh.")
            st.session_state['face_to_process'] = input_array

with col2:
    st.subheader("2. K·∫øt qu·∫£ d·ª± ƒëo√°n")
    
    if 'face_to_process' in st.session_state and input_image_pil is not None:
        if st.button("Ch·∫°y d·ª± ƒëo√°n", type="primary"):
            face_to_analyze = st.session_state['face_to_process']
            
            with st.spinner('ƒêang t√≠nh to√°n...'):
                try:
                    # 1. Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ ·∫£nh M·∫∂T (ch·ª© kh√¥ng ph·∫£i ·∫£nh g·ªëc)
                    features = extract_features_from_face(face_to_analyze, selector)
                    
                    emotion_labels = {0: "Gi·∫≠n d·ªØ üò°", 1: "S·ª£ h√£i üò±", 2: "Vui v·∫ª üòÑ", 3: "Bu·ªìn üò¢", 4: "Ng·∫°c nhi√™n üò≤"}
                    
                    # 2. Hi·ªÉn th·ªã k·∫øt qu·∫£
                    if not models:
                        st.error("Ch∆∞a t·∫£i ƒë∆∞·ª£c model.")
                    else:
                        st.write("---")
                        res_cols = st.columns(2)
                        for i, (name, model) in enumerate(models.items()):
                            pred = model.predict(features)[0]
                            label = emotion_labels.get(pred, str(pred))
                            
                            with res_cols[i % 2]:
                                st.success(f"**{name}**: {label}")
                                
                except Exception as e:
                    st.error(f"L·ªói: {e}")
    else:
        st.info("üëà Vui l√≤ng ch·ªçn ·∫£nh b√™n tr√°i tr∆∞·ªõc.")